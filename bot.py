# bot.py - –ü–û–õ–ù–´–ô –ö–û–î –° –ê–ù–ê–õ–ò–ó–û–ú –õ–ö–ü
import os
import telebot
from telebot import types
import logging
import requests
from bs4 import BeautifulSoup
import re
import json
import time
import cv2
import numpy as np
from PIL import Image
import io

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def reset_webhook(token):
    """–°–±—Ä–æ—Å webhook —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å polling"""
    try:
        url = f"https://api.telegram.org/bot{token}/deleteWebhook"
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            logger.info("‚úÖ Webhook reset successfully")
        else:
            logger.warning("‚ö†Ô∏è Could not reset webhook")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Webhook reset failed: {e}")

class PaintAnalyzer:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def analyze_paint_from_urls(self, image_urls):
        """–ê–Ω–∞–ª–∏–∑ –õ–ö–ü –ø–æ —Å—Å—ã–ª–∫–∞–º –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        if not image_urls:
            return {'error': '–ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞', 'score': 0}
        
        analyses = []
        analyzed_count = 0
        
        for img_url in image_urls[:3]:  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 3 —Ñ–æ—Ç–æ
            try:
                analysis = self.analyze_single_image(img_url)
                if analysis and analysis.get('score', 0) > 0:
                    analyses.append(analysis)
                    analyzed_count += 1
                    self.logger.info(f"‚úÖ Analyzed image {analyzed_count}")
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
                continue
        
        if not analyses:
            return {'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è', 'score': 0}
        
        return self.aggregate_analyses(analyses, analyzed_count)
    
    def analyze_single_image(self, image_url):
        """–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            response = requests.get(image_url, timeout=15)
            if response.status_code != 200:
                return None
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy array
            image = Image.open(io.BytesIO(response.content))
            img_array = np.array(image)
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if img_array.shape[0] < 100 or img_array.shape[1] < 100:
                return None
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ BGR –¥–ª—è OpenCV –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if len(img_array.shape) == 3 and img_array.shape[2] == 3:
                if img_array.shape[2] == 3:
                    img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
            else:
                # –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ grayscale, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                return None
            
            return self.analyze_image_features(img_array)
            
        except Exception as e:
            self.logger.error(f"Image analysis error: {e}")
            return None
    
    def analyze_image_features(self, img_array):
        """–ê–Ω–∞–ª–∏–∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –õ–ö–ü"""
        try:
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
            processed_img = self.preprocess_image(img_array)
            
            # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
            color_uniformity = self.analyze_color_uniformity(processed_img)
            edge_analysis = self.analyze_edges(processed_img)
            texture_analysis = self.analyze_texture(processed_img)
            brightness_analysis = self.analyze_brightness(processed_img)
            
            # –†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ —Å–∫–æ—Ä–∞
            overall_score = self.calculate_paint_score(
                color_uniformity, edge_analysis, texture_analysis, brightness_analysis
            )
            
            return {
                'score': overall_score,
                'color_uniformity': color_uniformity,
                'edge_quality': edge_analysis,
                'texture_smoothness': texture_analysis,
                'brightness_level': brightness_analysis
            }
            
        except Exception as e:
            self.logger.error(f"Feature analysis error: {e}")
            return {'score': 0}
    
    def preprocess_image(self, img_array):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–µ–∑–∫–æ—Å—Ç–∏
        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
        sharpened = cv2.filter2D(img_array, -1, kernel)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –æ—Å–≤–µ—â–µ–Ω–∏—è
        lab = cv2.cvtColor(sharpened, cv2.COLOR_BGR2LAB)
        lab[:,:,0] = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)).apply(lab[:,:,0])
        normalized = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
        
        return normalized
    
    def analyze_color_uniformity(self, img_array):
        """–ê–Ω–∞–ª–∏–∑ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏ —Ü–≤–µ—Ç–∞"""
        hsv = cv2.cvtColor(img_array, cv2.COLOR_BGR2HSV)
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç—Ç–µ–Ω–∫–∞ (–º–µ–Ω—å—à–µ = —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–µ–µ)
        hue_std = np.std(hsv[:,:,0])
        saturation_std = np.std(hsv[:,:,1])
        
        # –û—Ü–µ–Ω–∫–∞ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏ (0-100)
        uniformity_score = max(0, 100 - (hue_std * 0.5 + saturation_std * 0.2))
        
        return min(100, uniformity_score)
    
    def analyze_edges(self, img_array):
        """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑–∫–æ—Å—Ç–∏ –∏ –≥—Ä–∞–Ω–∏—Ü"""
        gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)
        
        # –î–µ—Ç–µ–∫—Ü–∏—è –∫—Ä–∞–µ–≤ (–±–æ–ª—å—à–µ –∫—Ä–∞–µ–≤ = –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.sum(edges > 0) / edges.size
        
        # –û—Ü–µ–Ω–∫–∞ —Ä–µ–∑–∫–æ—Å—Ç–∏ (0-100)
        sharpness_score = min(100, edge_density * 1000)
        
        return sharpness_score
    
    def analyze_texture(self, img_array):
        """–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç—É—Ä—ã –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏"""
        gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ª–∞–ø–ª–∞—Å–∏–∞–Ω–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ç–µ–∫—Å—Ç—É—Ä—ã
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        
        # –û—Ü–µ–Ω–∫–∞ –≥–ª–∞–¥–∫–æ—Å—Ç–∏ (–º–µ–Ω—å—à–µ –≤–∞—Ä–∏–∞—Ü–∏—è = –≥–ª–∞–∂–µ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å)
        smoothness_score = max(0, 100 - laplacian_var * 0.1)
        
        return min(100, smoothness_score)
    
    def analyze_brightness(self, img_array):
        """–ê–Ω–∞–ª–∏–∑ —è—Ä–∫–æ—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        hsv = cv2.cvtColor(img_array, cv2.COLOR_BGR2HSV)
        avg_brightness = np.mean(hsv[:,:,2])
        
        # –ò–¥–µ–∞–ª—å–Ω–∞—è —è—Ä–∫–æ—Å—Ç—å ~50-80%
        if 50 <= avg_brightness <= 80:
            brightness_score = 90
        elif 30 <= avg_brightness < 50 or 80 < avg_brightness <= 120:
            brightness_score = 70
        else:
            brightness_score = 40
        
        return brightness_score
    
    def calculate_paint_score(self, color_uniformity, edge_quality, texture_smoothness, brightness_level):
        """–†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ —Å–∫–æ—Ä–∞ –õ–ö–ü"""
        weights = {
            'color_uniformity': 0.4,    # –°–∞–º—ã–π –≤–∞–∂–Ω—ã–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å
            'edge_quality': 0.3,        # –†–µ–∑–∫–æ—Å—Ç—å –∏ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è
            'texture_smoothness': 0.2,  # –ì–ª–∞–¥–∫–æ—Å—Ç—å –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏
            'brightness_level': 0.1     # –ö–∞—á–µ—Å—Ç–≤–æ –æ—Å–≤–µ—â–µ–Ω–∏—è
        }
        
        total_score = (
            color_uniformity * weights['color_uniformity'] +
            edge_quality * weights['edge_quality'] +
            texture_smoothness * weights['texture_smoothness'] +
            brightness_level * weights['brightness_level']
        )
        
        return min(100, int(total_score))
    
    def aggregate_analyses(self, analyses, count):
        """–ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
        if not analyses:
            return {'score': 0, 'message': '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞'}
        
        total_score = sum(analysis['score'] for analysis in analyses)
        avg_score = total_score / len(analyses)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –õ–ö–ü –ø–æ —Å—Ä–µ–¥–Ω–µ–º—É —Å–∫–æ—Ä—É
        if avg_score >= 80:
            condition = "–æ—Ç–ª–∏—á–Ω–æ–µ"
            emoji = "üé®"
        elif avg_score >= 60:
            condition = "—Ö–æ—Ä–æ—à–µ–µ" 
            emoji = "‚úÖ"
        elif avg_score >= 40:
            condition = "—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ"
            emoji = "‚ö†Ô∏è"
        else:
            condition = "—Ç—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è"
            emoji = "üîß"
        
        return {
            'score': int(avg_score),
            'condition': condition,
            'emoji': emoji,
            'analyzed_images': count,
            'message': f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"
        }

class SimpleAvitoBot:
    def __init__(self, token):
        self.bot = telebot.TeleBot(token)
        self.paint_analyzer = PaintAnalyzer()
        self.setup_handlers()
        logger.info("‚úÖ Bot initialized successfully!")
    
    def setup_handlers(self):
        @self.bot.message_handler(commands=['start', 'help'])
        def start_handler(message):
            self.handle_start(message)
        
        @self.bot.message_handler(regexp=r'https?://(www\.)?avito\.ru/.*')
        def avito_url_handler(message):
            self.handle_avito_url(message)
        
        @self.bot.message_handler(regexp=r'https?://(www\.)?drom\.ru/.*')
        def drom_url_handler(message):
            self.handle_drom_url(message)
        
        @self.bot.message_handler(func=lambda message: True)
        def text_handler(message):
            self.handle_text(message)
    
    def handle_start(self, message):
        chat_id = message.chat.id
        
        markup = types.ReplyKeyboardMarkup(resize_keyboard=True)
        markup.add('üîç –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä—è–≤–ª–µ–Ω–∏–µ')
        markup.add('‚ÑπÔ∏è –ü–æ–º–æ—â—å')
        
        welcome_text = """
üöó *AutoInspect Bot*

–í–∞—à –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–π —Å:
‚Ä¢ üÖ∞Ô∏è –ê–≤–∏—Ç–æ
‚Ä¢ üá© Drom.ru

*–ß—Ç–æ —è –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é:*
‚Ä¢ üìä –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–≤—Ç–æ
‚Ä¢ üí∞ –ê–¥–µ–∫–≤–∞—Ç–Ω–æ—Å—Ç—å —Ü–µ–Ω—ã  
‚Ä¢ üé® –°–æ—Å—Ç–æ—è–Ω–∏–µ –õ–ö–ü –ø–æ —Ñ–æ—Ç–æ
‚Ä¢ üì∏ –ö–∞—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π

*–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:*
–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ!

–ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –Ω–∏–∂–µ —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å! üëá
        """
        
        self.bot.send_message(
            chat_id,
            welcome_text,
            reply_markup=markup,
            parse_mode='Markdown'
        )
    
    def handle_avito_url(self, message):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Å—ã–ª–æ–∫ —Å –ê–≤–∏—Ç–æ"""
        chat_id = message.chat.id
        url = message.text
        
        logger.info(f"üîó Received Avito URL: {url}")
        
        try:
            status_msg = self.bot.send_message(
                chat_id, 
                "üîç *–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –æ–±—ä—è–≤–ª–µ–Ω–∏–µ —Å –ê–≤–∏—Ç–æ...*", 
                parse_mode='Markdown'
            )
            
            self.bot.edit_message_text(
                "üì¶ *–ü–æ–ª—É—á–∞—é –¥–∞–Ω–Ω—ã–µ...*",
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            ad_data = self.parse_avito_ad(url)
            
            if not ad_data:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è")
            
            self.bot.edit_message_text(
                "üìä *–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –ø–∞—Ä–∞–º–µ—Ç—Ä—ã...*",
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            analysis = self.analyze_ad(ad_data)
            
            self.bot.edit_message_text(
                "üé® *–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –õ–ö–ü –ø–æ —Ñ–æ—Ç–æ...*",
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            # –ê–Ω–∞–ª–∏–∑ –õ–ö–ü
            paint_analysis = self.paint_analyzer.analyze_paint_from_urls(ad_data['images'])
            analysis['paint_analysis'] = paint_analysis
            
            self.bot.edit_message_text(
                "üìù *–§–æ—Ä–º–∏—Ä—É—é –æ—Ç—á–µ—Ç...*",
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            report = self.generate_report(ad_data, analysis)
            
            self.bot.edit_message_text(
                report,
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            logger.info(f"‚úÖ Avito analysis completed: {url}")
            
        except Exception as e:
            logger.error(f"‚ùå Avito analysis failed: {e}")
            error_msg = f"‚ùå *–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ê–≤–∏—Ç–æ:* {str(e)}"
            try:
                self.bot.edit_message_text(
                    error_msg,
                    chat_id,
                    status_msg.message_id,
                    parse_mode='Markdown'
                )
            except:
                self.bot.send_message(chat_id, error_msg, parse_mode='Markdown')
    
    def handle_drom_url(self, message):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Å—ã–ª–æ–∫ —Å Drom.ru"""
        chat_id = message.chat.id
        url = message.text
        
        logger.info(f"üîó Received Drom URL: {url}")
        
        try:
            status_msg = self.bot.send_message(
                chat_id, 
                "üîç *–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –æ–±—ä—è–≤–ª–µ–Ω–∏–µ —Å Drom...*", 
                parse_mode='Markdown'
            )
            
            self.bot.edit_message_text(
                "üì¶ *–ü–æ–ª—É—á–∞—é –¥–∞–Ω–Ω—ã–µ...*",
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            ad_data = self.parse_drom_ad(url)
            
            if not ad_data:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è")
            
            self.bot.edit_message_text(
                "üìä *–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –ø–∞—Ä–∞–º–µ—Ç—Ä—ã...*",
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            analysis = self.analyze_ad(ad_data)
            
            self.bot.edit_message_text(
                "üé® *–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –õ–ö–ü –ø–æ —Ñ–æ—Ç–æ...*",
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            # –ê–Ω–∞–ª–∏–∑ –õ–ö–ü
            paint_analysis = self.paint_analyzer.analyze_paint_from_urls(ad_data['images'])
            analysis['paint_analysis'] = paint_analysis
            
            self.bot.edit_message_text(
                "üìù *–§–æ—Ä–º–∏—Ä—É—é –æ—Ç—á–µ—Ç...*",
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            report = self.generate_report(ad_data, analysis)
            
            self.bot.edit_message_text(
                report,
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            logger.info(f"‚úÖ Drom analysis completed: {url}")
            
        except Exception as e:
            logger.error(f"‚ùå Drom analysis failed: {e}")
            error_msg = f"‚ùå *–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ Drom:* {str(e)}"
            try:
                self.bot.edit_message_text(
                    error_msg,
                    chat_id,
                    status_msg.message_id,
                    parse_mode='Markdown'
                )
            except:
                self.bot.send_message(chat_id, error_msg, parse_mode='Markdown')
    
    def parse_avito_ad(self, url):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å –ê–≤–∏—Ç–æ"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            }
            
            response = requests.get(url, headers=headers, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            title = self.extract_avito_title(soup)
            # –¶–µ–Ω–∞
            price = self.extract_avito_price(soup, response.text)
            # –§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
            images = self.extract_avito_images(soup)
            # –ì–æ–¥
            year = self.extract_year(title)
            # –†–µ–≥–∏–æ–Ω
            region = self.extract_avito_region(url)
            
            return {
                'title': title,
                'price': price,
                'year': year,
                'region': region,
                'image_count': len(images),
                'images': images,
                'url': url,
                'source': 'avito'
            }
            
        except Exception as e:
            logger.error(f"‚ùå Avito parsing failed: {e}")
            return None
    
    def parse_drom_ad(self, url):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å Drom.ru"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            }
            
            response = requests.get(url, headers=headers, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            title = self.extract_drom_title(soup)
            # –¶–µ–Ω–∞
            price = self.extract_drom_price(soup, response.text)
            # –§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
            images = self.extract_drom_images(soup)
            # –ì–æ–¥
            year = self.extract_drom_year(soup, title)
            # –†–µ–≥–∏–æ–Ω
            region = self.extract_drom_region(soup)
            
            return {
                'title': title,
                'price': price,
                'year': year,
                'region': region,
                'image_count': len(images),
                'images': images,
                'url': url,
                'source': 'drom'
            }
            
        except Exception as e:
            logger.error(f"‚ùå Drom parsing failed: {e}")
            return None
    
    def extract_avito_title(self, soup):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Å –ê–≤–∏—Ç–æ"""
        try:
            selectors = [
                'h1[data-marker="item-view/title"]',
                'h1.title-info-title',
                'h1',
                '.title-info-title-text',
                '[data-marker="item-view/title"]'
            ]
            
            for selector in selectors:
                element = soup.select_one(selector)
                if element and element.get_text(strip=True):
                    return element.get_text(strip=True)
            
            meta_title = soup.find('meta', property='og:title')
            if meta_title and meta_title.get('content'):
                return meta_title['content']
            
            page_title = soup.find('title')
            if page_title:
                return page_title.get_text(strip=True)
            
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å"
            
        except Exception as e:
            logger.error(f"Avito title error: {e}")
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å"
    
    def extract_drom_title(self, soup):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Å Drom"""
        try:
            selectors = [
                'h1[class*="title"]',
                '.css-1tjirrw',
                'h1',
                '[data-ftid="component_ad_title"]'
            ]
            
            for selector in selectors:
                element = soup.select_one(selector)
                if element and element.get_text(strip=True):
                    return element.get_text(strip=True)
            
            meta_title = soup.find('meta', property='og:title')
            if meta_title and meta_title.get('content'):
                return meta_title['content']
            
            page_title = soup.find('title')
            if page_title:
                return page_title.get_text(strip=True)
            
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å"
            
        except Exception as e:
            logger.error(f"Drom title error: {e}")
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å"
    
    def extract_avito_price(self, soup, page_text):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω—ã —Å –ê–≤–∏—Ç–æ"""
        try:
            price_selectors = [
                'meta[itemprop="price"]',
                'span[data-marker="item-view/item-price"]',
                '[data-marker="item-view/item-price"]',
                '.js-item-price',
                '.price-value',
            ]
            
            for selector in price_selectors:
                element = soup.select_one(selector)
                if element:
                    if element.get('content'):
                        price_str = element['content']
                        if price_str.isdigit():
                            return int(price_str)
                    
                    price_text = element.get_text(strip=True)
                    numbers = re.findall(r'\d+', price_text.replace(' ', ''))
                    if numbers:
                        return int(''.join(numbers))
            
            # –ü–æ–∏—Å–∫ –≤ JSON-LD
            json_ld = soup.find('script', type='application/ld+json')
            if json_ld:
                try:
                    data = json.loads(json_ld.string)
                    if 'offers' in data and 'price' in data['offers']:
                        return int(data['offers']['price'])
                except:
                    pass
            
            # –ü–æ–∏—Å–∫ –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            price_patterns = [
                r'"price":\s*"(\d+)"',
                r'"price":\s*(\d+)',
                r'itemprop="price".*?content="(\d+)"',
            ]
            
            for pattern in price_patterns:
                matches = re.search(pattern, page_text, re.IGNORECASE | re.DOTALL)
                if matches:
                    price_str = matches.group(1).replace(' ', '')
                    if price_str.isdigit():
                        return int(price_str)
            
            return 0
            
        except Exception as e:
            logger.error(f"Avito price error: {e}")
            return 0
    
    def extract_drom_price(self, soup, page_text):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω—ã —Å Drom"""
        try:
            price_selectors = [
                '[data-ftid="component_price"]',
                '.css-1dv8a3k',
                '.css-1v9f1fg',
                '[class*="price"]'
            ]
            
            for selector in price_selectors:
                element = soup.select_one(selector)
                if element:
                    price_text = element.get_text(strip=True)
                    numbers = re.findall(r'\d+', price_text.replace(' ', ''))
                    if numbers:
                        return int(''.join(numbers))
            
            # –ü–æ–∏—Å–∫ –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            price_patterns = [
                r'"price":\s*"(\d+)"',
                r'"price":\s*(\d+)',
                r'—Ü–µ–Ω–∞.*?(\d[\d\s]*)\s*‚ÇΩ',
            ]
            
            for pattern in price_patterns:
                matches = re.search(pattern, page_text, re.IGNORECASE | re.DOTALL)
                if matches:
                    price_str = matches.group(1).replace(' ', '')
                    if price_str.isdigit():
                        return int(price_str)
            
            return 0
            
        except Exception as e:
            logger.error(f"Drom price error: {e}")
            return 0
    
    def extract_avito_images(self, soup):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ê–≤–∏—Ç–æ"""
        try:
            images = []
            
            img_selectors = [
                'img[data-src]',
                'img[src*="avito"]',
                '.gallery-img-cover img',
                '[data-marker="image-frame/image"]',
            ]
            
            for selector in img_selectors:
                img_elements = soup.select(selector)
                for img in img_elements[:10]:
                    src = img.get('data-src') or img.get('src')
                    if src and src.startswith('http'):
                        if src.startswith('//'):
                            src = 'https:' + src
                        images.append(src)
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            unique_images = []
            for img in images:
                if img not in unique_images:
                    unique_images.append(img)
            
            return unique_images
            
        except Exception as e:
            logger.error(f"Avito images error: {e}")
            return []
    
    def extract_drom_images(self, soup):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å Drom"""
        try:
            images = []
            
            img_selectors = [
                'img[src*="drom"]',
                '.css-1bm2a1l img',
                '.b-album__item img',
                '[data-ftid="component_gallery_image"]'
            ]
            
            for selector in img_selectors:
                img_elements = soup.select(selector)
                for img in img_elements[:10]:
                    src = img.get('src')
                    if src and src.startswith('http'):
                        if src.startswith('//'):
                            src = 'https:' + src
                        images.append(src)
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            unique_images = []
            for img in images:
                if img not in unique_images:
                    unique_images.append(img)
            
            return unique_images
            
        except Exception as e:
            logger.error(f"Drom images error: {e}")
            return []
    
    def extract_year(self, title):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥–æ–¥–∞ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        try:
            year_match = re.search(r'\b(19|20)\d{2}\b', title)
            return int(year_match.group()) if year_match else 2020
        except:
            return 2020
    
    def extract_drom_year(self, soup, title):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥–æ–¥–∞ —Å Drom"""
        try:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            year_match = re.search(r'\b(19|20)\d{2}\b', title)
            if year_match:
                return int(year_match.group())
            
            # –ò—â–µ–º –≤ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ö
            year_selectors = [
                '[data-ftid="component_inline-param"]',
                '.css-1ei9tni',
                '[class*="year"]'
            ]
            
            for selector in year_selectors:
                elements = soup.select(selector)
                for element in elements:
                    text = element.get_text()
                    year_match = re.search(r'\b(19|20)\d{2}\b', text)
                    if year_match:
                        return int(year_match.group())
            
            return 2020
            
        except:
            return 2020
    
    def extract_avito_region(self, url):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞ –∏–∑ URL –ê–≤–∏—Ç–æ"""
        try:
            match = re.search(r'avito\.ru/([^/]+)', url)
            if match:
                region = match.group(1)
                region_map = {
                    'moskva': '–ú–æ—Å–∫–≤–∞',
                    'sankt-peterburg': '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥',
                    'spb': '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥',
                    'novosibirsk': '–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫',
                    'ekaterinburg': '–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥',
                    'kazan': '–ö–∞–∑–∞–Ω—å',
                }
                return region_map.get(region, region.replace('-', ' ').title())
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        except:
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
    
    def extract_drom_region(self, soup):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞ —Å Drom"""
        try:
            region_selectors = [
                '[data-ftid="component_seller_location"]',
                '.css-1l12n0z',
                '[class*="location"]'
            ]
            
            for selector in region_selectors:
                element = soup.select_one(selector)
                if element:
                    region_text = element.get_text(strip=True)
                    if region_text:
                        return region_text
            
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        except:
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
    
    def analyze_ad(self, ad_data):
        """–ê–Ω–∞–ª–∏–∑ –æ–±—ä—è–≤–ª–µ–Ω–∏—è"""
        analysis = {
            'price_analysis': self.analyze_price(ad_data['price']),
            'photo_analysis': self.analyze_photos(ad_data['image_count']),
            'year_analysis': self.analyze_year(ad_data['year']),
            'recommendations': []
        }
        
        recommendations = self.generate_recommendations(ad_data, analysis)
        analysis['recommendations'] = recommendations
        
        analysis['overall_score'] = self.calculate_overall_score(ad_data, analysis)
        
        return analysis
    
    def analyze_price(self, price):
        if price == 0:
            return {'emoji': '‚ùì', 'text': '–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞', 'score': 3}
        elif price < 100000:
            return {'emoji': 'üö®', 'text': '–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –Ω–∏–∑–∫–∞—è', 'score': 1}
        elif price < 300000:
            return {'emoji': 'üí∞', 'text': '–ù–∏–∑–∫–∞—è', 'score': 7}
        elif price < 800000:
            return {'emoji': 'üíµ', 'text': '–°—Ä–µ–¥–Ω—è—è', 'score': 8}
        elif price < 2000000:
            return {'emoji': 'üíé', 'text': '–í—ã—Å–æ–∫–∞—è', 'score': 6}
        else:
            return {'emoji': 'üèéÔ∏è', 'text': '–ü—Ä–µ–º–∏—É–º', 'score': 5}
    
    def analyze_photos(self, image_count):
        if image_count == 0:
            return {'emoji': '‚ùå', 'text': '–ù–µ—Ç —Ñ–æ—Ç–æ', 'score': 1}
        elif image_count < 3:
            return {'emoji': '‚ö†Ô∏è', 'text': '–ú–∞–ª–æ —Ñ–æ—Ç–æ', 'score': 5}
        elif image_count < 6:
            return {'emoji': '‚úÖ', 'text': '–î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ', 'score': 8}
        else:
            return {'emoji': 'üì∏', 'text': '–ú–Ω–æ–≥–æ —Ñ–æ—Ç–æ', 'score': 9}
    
    def analyze_year(self, year):
        car_age = 2024 - year
        
        if car_age <= 3:
            return {'emoji': 'üÜï', 'text': '–ù–æ–≤—ã–π', 'score': 9}
        elif car_age <= 7:
            return {'emoji': '‚úÖ', 'text': '–°—Ä–µ–¥–Ω–∏–π –≤–æ–∑—Ä–∞—Å—Ç', 'score': 7}
        elif car_age <= 12:
            return {'emoji': '‚ö†Ô∏è', 'text': '–°—Ç–∞—Ä—ã–π', 'score': 5}
        else:
            return {'emoji': 'üöó', 'text': '–í–µ—Ç–µ—Ä–∞–Ω', 'score': 3}
    
    def calculate_overall_score(self, ad_data, analysis):
        scores = [
            analysis['price_analysis']['score'],
            analysis['photo_analysis']['score'],
            analysis['year_analysis']['score']
        ]
        
        return round(sum(scores) / len(scores))
    
    def generate_recommendations(self, ad_data, analysis):
        recommendations = []
        
        if ad_data['image_count'] == 0:
            recommendations.append("‚ùå *–ù–µ—Ç —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π* - –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∑–∞–ø—Ä–æ—Å–∏—Ç–µ —É –ø—Ä–æ–¥–∞–≤—Ü–∞")
        elif ad_data['image_count'] < 3:
            recommendations.append("‚ö†Ô∏è *–ú–∞–ª–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π* - –ø–æ–ø—Ä–æ—Å–∏—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–æ—Ç–æ")
        
        if ad_data['price'] == 0:
            recommendations.append("‚ùì *–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞* - —É—Ç–æ—á–Ω–∏—Ç–µ —Å—Ç–æ–∏–º–æ—Å—Ç—å")
        elif ad_data['price'] < 100000:
            recommendations.append("üö® *–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –Ω–∏–∑–∫–∞—è —Ü–µ–Ω–∞* - –±—É–¥—å—Ç–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã")
        
        if 2024 - ad_data['year'] > 15:
            recommendations.append("üï∞Ô∏è *–ê–≤—Ç–æ–º–æ–±–∏–ª—å —Å—Ç–∞—Ä—à–µ 15 –ª–µ—Ç* - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ")
        
        if not recommendations:
            recommendations.append("‚úÖ *–û–±—ä—è–≤–ª–µ–Ω–∏–µ –≤—ã–≥–ª—è–¥–∏—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ* - –º–æ–∂–Ω–æ –¥–æ–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å—Å—è –æ –æ—Å–º–æ—Ç—Ä–µ")
        
        return recommendations
    
    def generate_report(self, ad_data, analysis):
        source_emoji = "üÖ∞Ô∏è" if ad_data['source'] == 'avito' else "üá©"
        paint_analysis = analysis.get('paint_analysis', {})
        
        report = f"""
{source_emoji} *{ad_data['title']}*

üí∞ *–¶–µ–Ω–∞:* {ad_data['price']:,} —Ä—É–±. {analysis['price_analysis']['emoji']}
üìÖ *–ì–æ–¥:* {ad_data['year']} {analysis['year_analysis']['emoji']}
üìç *–†–µ–≥–∏–æ–Ω:* {ad_data['region']}
üì∏ *–§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏:* {ad_data['image_count']} {analysis['photo_analysis']['emoji']}

‚≠ê *–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞:* {analysis['overall_score']}/10

üé® *–ê–Ω–∞–ª–∏–∑ –õ–ö–ü:* {paint_analysis.get('score', 0)}/100 {paint_analysis.get('emoji', '‚ùì')}
‚Ä¢ –°–æ—Å—Ç–æ—è–Ω–∏–µ: {paint_analysis.get('condition', '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ')}
‚Ä¢ {paint_analysis.get('message', '–ê–Ω–∞–ª–∏–∑ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω')}

üìä *–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑:*
‚Ä¢ –¶–µ–Ω–∞: {analysis['price_analysis']['text']}
‚Ä¢ –§–æ—Ç–æ: {analysis['photo_analysis']['text']}
‚Ä¢ –í–æ–∑—Ä–∞—Å—Ç: {analysis['year_analysis']['text']}

üí° *–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:*
"""
        
        for rec in analysis['recommendations']:
            report += f"‚Ä¢ {rec}\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –õ–ö–ü
        paint_score = paint_analysis.get('score', 0)
        if paint_score > 0:
            if paint_score < 40:
                report += "‚Ä¢ üé® *–°–æ—Å—Ç–æ—è–Ω–∏–µ –õ–ö–ü –ø–ª–æ—Ö–æ–µ* - –≤–æ–∑–º–æ–∂–Ω—ã —Ü–∞—Ä–∞–ø–∏–Ω—ã –∏ –¥–µ—Ñ–µ–∫—Ç—ã\n"
            elif paint_score < 70:
                report += "‚Ä¢ üé® *–°–æ—Å—Ç–æ—è–Ω–∏–µ –õ–ö–ü —Å—Ä–µ–¥–Ω–µ–µ* - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ—Å–º–æ—Ç—Ä\n"
            else:
                report += "‚Ä¢ üé® *–°–æ—Å—Ç–æ—è–Ω–∏–µ –õ–ö–ü —Ö–æ—Ä–æ—à–µ–µ* - –ø–æ —Ñ–æ—Ç–æ –≤—ã–≥–ª—è–¥–∏—Ç –æ—Ç–ª–∏—á–Ω–æ\n"
        
        report += f"""
üîç *–°–æ–≤–µ—Ç—ã –ø–æ –æ—Å–º–æ—Ç—Ä—É:*
‚Ä¢ –í—Å–µ–≥–¥–∞ –æ—Å–º–∞—Ç—Ä–∏–≤–∞–π—Ç–µ –∞–≤—Ç–æ–º–æ–±–∏–ª—å –ª–∏—á–Ω–æ
‚Ä¢ –ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ VIN
‚Ä¢ –°–¥–µ–ª–∞–π—Ç–µ —Ç–µ—Å—Ç-–¥—Ä–∞–π–≤
‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å—Ç–æ—Ä–∏—é —á–µ—Ä–µ–∑ –æ–Ω–ª–∞–π–Ω-—Å–µ—Ä–≤–∏—Å—ã
‚Ä¢ –û—Å–æ–±–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ —É–¥–µ–ª–∏—Ç–µ —Å–æ—Å—Ç–æ—è–Ω–∏—é –∫—É–∑–æ–≤–∞

üéØ *–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:*
–°–≤—è–∂–∏—Ç–µ—Å—å —Å –ø—Ä–æ–¥–∞–≤—Ü–æ–º –∏ –¥–æ–≥–æ–≤–æ—Ä–∏—Ç–µ—Å—å –æ –æ—Å–º–æ—Ç—Ä–µ!
        """
        
        return report
    
    def handle_text(self, message):
        chat_id = message.chat.id
        text = message.text
        
        if text == 'üîç –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä—è–≤–ª–µ–Ω–∏–µ':
            self.bot.send_message(
                chat_id,
                "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ:\n\n*–ê–≤–∏—Ç–æ:*\n`https://www.avito.ru/...`\n\n*Drom:*\n`https://auto.drom.ru/...`",
                parse_mode='Markdown'
            )
        
        elif text == '‚ÑπÔ∏è –ü–æ–º–æ—â—å':
            help_text = """
ü§ñ *AutoInspect Bot - –ü–æ–º–æ—â—å*

*–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–ª–æ—â–∞–¥–∫–∏:*
‚Ä¢ üÖ∞Ô∏è –ê–≤–∏—Ç–æ (avito.ru)
‚Ä¢ üá© Drom.ru (auto.drom.ru)

*–ß—Ç–æ —è –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é:*
‚Ä¢ üìä –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–≤—Ç–æ–º–æ–±–∏–ª—è
‚Ä¢ üí∞ –ê–¥–µ–∫–≤–∞—Ç–Ω–æ—Å—Ç—å —Ü–µ–Ω—ã
‚Ä¢ üé® –°–æ—Å—Ç–æ—è–Ω–∏–µ –õ–ö–ü –ø–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è–º (–∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ)
‚Ä¢ üì∏ –ù–∞–ª–∏—á–∏–µ –∏ –∫–∞—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π
‚Ä¢ üìÖ –ì–æ–¥ –≤—ã–ø—É—Å–∫–∞ –∏ –≤–æ–∑—Ä–∞—Å—Ç –∞–≤—Ç–æ–º–æ–±–∏–ª—è

*–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:*
1. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ
2. –Ø –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
3. –í—ã –ø–æ–ª—É—á–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç —Å –æ—Ü–µ–Ω–∫–æ–π –õ–ö–ü

*–ü—Ä–∏–º–µ—Ä—ã —Å—Å—ã–ª–æ–∫:*
`https://www.avito.ru/moskva/avtomobili/...`
`https://auto.drom.ru/volkswagen/golf/...`

*–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:* –ê–Ω–∞–ª–∏–∑ –õ–ö–ü –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è–º. –í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –∞–≤—Ç–æ–º–æ–±–∏–ª—å –ª–∏—á–Ω–æ!
            """
            self.bot.send_message(chat_id, help_text, parse_mode='Markdown')
        
        else:
            self.bot.send_message(
                chat_id,
                "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –Ω–∏–∂–µ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ —Å –ê–≤–∏—Ç–æ –∏–ª–∏ Drom üëá"
            )
    
    def run(self):
        """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        logger.info("üöÄ Starting AutoInspect Bot...")
        
        max_retries = 3
        retry_delay = 10
        
        for attempt in range(max_retries):
            try:
                logger.info(f"üîÑ Attempt {attempt + 1} to start bot...")
                self.bot.infinity_polling(timeout=60, long_polling_timeout=60)
                break
            except Exception as e:
                logger.error(f"‚ùå Bot crashed on attempt {attempt + 1}: {e}")
                
                if attempt < max_retries - 1:
                    logger.info(f"üïê Retrying in {retry_delay} seconds...")
                    time.sleep(retry_delay)
                    retry_delay *= 2
                else:
                    logger.error("‚ùå All retry attempts failed. Bot stopped.")
                    raise

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if __name__ == "__main__":
    token = os.getenv('BOT_TOKEN')
    
    if not token:
        logger.error("‚ùå BOT_TOKEN environment variable is not set!")
        exit(1)
    
    # –°–±—Ä–æ—Å webhook –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º
    reset_webhook(token)
    
    # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏–∏ —Å–±—Ä–æ—Å–∞ webhook
    time.sleep(2)
    
    # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞
    bot = SimpleAvitoBot(token)
    bot.run()
