# bot.py - –í–ï–†–°–ò–Ø –ë–ï–ó LXML
import os
import telebot
from telebot import types
import logging
import requests
from bs4 import BeautifulSoup
import re
import json
from urllib.parse import urljoin

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SimpleAvitoBot:
    def __init__(self, token):
        self.bot = telebot.TeleBot(token)
        self.setup_handlers()
        logger.info("‚úÖ Bot initialized successfully!")
    
    def setup_handlers(self):
        @self.bot.message_handler(commands=['start', 'help'])
        def start_handler(message):
            self.handle_start(message)
        
        @self.bot.message_handler(regexp=r'https?://(www\.)?avito\.ru/.*')
        def url_handler(message):
            self.handle_avito_url(message)
        
        @self.bot.message_handler(func=lambda message: True)
        def text_handler(message):
            self.handle_text(message)
    
    def handle_start(self, message):
        chat_id = message.chat.id
        
        markup = types.ReplyKeyboardMarkup(resize_keyboard=True)
        markup.add('üîç –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä—è–≤–ª–µ–Ω–∏–µ')
        markup.add('‚ÑπÔ∏è –ü–æ–º–æ—â—å')
        
        welcome_text = """
üöó *AutoInspect Bot*

–ü—Ä–æ—Å—Ç–æ–π –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–π —Å –ê–≤–∏—Ç–æ.

*–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:*
1. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ —Å –ê–≤–∏—Ç–æ
2. –ü–æ–ª—É—á–∏—Ç–µ –±–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

*–ü—Ä–∏–º–µ—Ä —Å—Å—ã–ª–∫–∏:*
`https://www.avito.ru/moskva/avtomobili/volkswagen_golf_2018...`

–ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –Ω–∏–∂–µ —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å! üëá
        """
        
        self.bot.send_message(
            chat_id,
            welcome_text,
            reply_markup=markup,
            parse_mode='Markdown'
        )
    
    def handle_avito_url(self, message):
        chat_id = message.chat.id
        url = message.text
        
        try:
            # –°—Ç–∞—Ç—É—Å –∞–Ω–∞–ª–∏–∑–∞
            status_msg = self.bot.send_message(
                chat_id, 
                "üîç *–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –æ–±—ä—è–≤–ª–µ–Ω–∏–µ...*", 
                parse_mode='Markdown'
            )
            
            # –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ
            self.bot.edit_message_text(
                "üì¶ *–ü–æ–ª—É—á–∞—é –¥–∞–Ω–Ω—ã–µ...*",
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            ad_data = self.parse_avito_ad(url)
            
            if not ad_data:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º
            self.bot.edit_message_text(
                "üìä *–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é...*",
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            analysis = self.analyze_ad(ad_data)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
            self.bot.edit_message_text(
                "üìù *–§–æ—Ä–º–∏—Ä—É—é –æ—Ç—á–µ—Ç...*",
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            report = self.generate_report(ad_data, analysis)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self.bot.edit_message_text(
                report,
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            logger.info(f"‚úÖ Successfully analyzed: {url}")
            
        except Exception as e:
            error_msg = f"‚ùå *–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞:* {str(e)}"
            try:
                self.bot.edit_message_text(
                    error_msg,
                    chat_id,
                    status_msg.message_id,
                    parse_mode='Markdown'
                )
            except:
                self.bot.send_message(chat_id, error_msg, parse_mode='Markdown')
            
            logger.error(f"‚ùå Analysis failed: {e}")
    
    def parse_avito_ad(self, url):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å –ê–≤–∏—Ç–æ –±–µ–∑ lxml"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
            }
            
            response = requests.get(url, headers=headers, timeout=15)
            response.raise_for_status()
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π html.parser –≤–º–µ—Å—Ç–æ lxml
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            title = self.extract_title(soup)
            price = self.extract_price(soup, response.text)
            images = self.extract_images(soup)
            year = self.extract_year(title)
            region = self.extract_region(url)
            mileage = self.extract_mileage(soup, response.text)
            
            return {
                'title': title,
                'price': price,
                'year': year,
                'region': region,
                'mileage': mileage,
                'image_count': len(images),
                'images': images[:5],  # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 5 —Ñ–æ—Ç–æ
                'url': url
            }
            
        except Exception as e:
            logger.error(f"‚ùå Parsing failed: {e}")
            return None
    
    def extract_title(self, soup):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        try:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
            selectors = [
                'h1[data-marker="item-view/title"]',
                'h1.title-info-title',
                'h1',
                '.title-info-title-text',
                '[data-marker="item-view/title"]'
            ]
            
            for selector in selectors:
                element = soup.select_one(selector)
                if element and element.get_text(strip=True):
                    return element.get_text(strip=True)
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º, –∏—â–µ–º –≤ –º–µ—Ç–∞-—Ç–µ–≥–∞—Ö
            meta_title = soup.find('meta', property='og:title')
            if meta_title and meta_title.get('content'):
                return meta_title['content']
            
            # –ò—â–µ–º –≤ title —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            page_title = soup.find('title')
            if page_title:
                return page_title.get_text(strip=True)
            
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å"
            
        except Exception as e:
            logger.error(f"Title extraction error: {e}")
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å"
    
    def extract_price(self, soup, page_text):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω—ã"""
        try:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –Ω–∞–π—Ç–∏ —Ü–µ–Ω—É
            price_selectors = [
                'meta[itemprop="price"]',
                'span[data-marker="item-view/item-price"]',
                '[data-marker="item-view/item-price"]',
                '.js-item-price',
                '.price-value',
                '.style-item-price-text-_w822'
            ]
            
            for selector in price_selectors:
                element = soup.select_one(selector)
                if element:
                    # –ü—Ä–æ–±—É–µ–º –∏–∑ –∞—Ç—Ä–∏–±—É—Ç–∞ content
                    if element.get('content'):
                        price_str = element['content']
                        if price_str.isdigit():
                            return int(price_str)
                    
                    # –ü—Ä–æ–±—É–µ–º –∏–∑ —Ç–µ–∫—Å—Ç–∞
                    price_text = element.get_text(strip=True)
                    numbers = re.findall(r'\d+', price_text.replace(' ', ''))
                    if numbers:
                        return int(''.join(numbers))
            
            # –ò—â–µ–º –≤ JSON-LD
            json_ld = soup.find('script', type='application/ld+json')
            if json_ld:
                try:
                    data = json.loads(json_ld.string)
                    if 'offers' in data and 'price' in data['offers']:
                        return int(data['offers']['price'])
                except:
                    pass
            
            # –ò—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º–∏
            price_patterns = [
                r'"price":\s*"(\d+)"',
                r'"price":\s*(\d+)',
                r'itemprop="price".*?content="(\d+)"',
                r'data-marker="item-view/item-price".*?>.*?(\d[\d\s]*)\s*‚ÇΩ'
            ]
            
            for pattern in price_patterns:
                matches = re.search(pattern, page_text, re.IGNORECASE | re.DOTALL)
                if matches:
                    price_str = matches.group(1).replace(' ', '')
                    if price_str.isdigit():
                        return int(price_str)
            
            return 0
            
        except Exception as e:
            logger.error(f"Price extraction error: {e}")
            return 0
    
    def extract_images(self, soup):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        try:
            images = []
            
            # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –≥–∞–ª–µ—Ä–µ–µ
            img_selectors = [
                'img[data-src]',
                'img[src*="avito"]',
                '.gallery-img-cover img',
                '[data-marker="image-frame/image"]',
                '.photo-slider-image-img'
            ]
            
            for selector in img_selectors:
                img_elements = soup.select(selector)
                for img in img_elements[:10]:  # –ú–∞–∫—Å–∏–º—É–º 10 —Ñ–æ—Ç–æ
                    src = img.get('data-src') or img.get('src')
                    if src and src.startswith('http'):
                        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL
                        if src.startswith('//'):
                            src = 'https:' + src
                        images.append(src)
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            unique_images = []
            for img in images:
                if img not in unique_images:
                    unique_images.append(img)
            
            return unique_images
            
        except Exception as e:
            logger.error(f"Image extraction error: {e}")
            return []
    
    def extract_year(self, title):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥–æ–¥–∞ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        try:
            year_match = re.search(r'\b(19|20)\d{2}\b', title)
            return int(year_match.group()) if year_match else 2020
        except:
            return 2020
    
    def extract_region(self, url):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞ –∏–∑ URL"""
        try:
            match = re.search(r'avito\.ru/([^/]+)', url)
            if match:
                region = match.group(1)
                # –ö—Ä–∞—Å–∏–≤–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞
                region_map = {
                    'moskva': '–ú–æ—Å–∫–≤–∞',
                    'sankt-peterburg': '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥',
                    'spb': '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥',
                    'novosibirsk': '–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫',
                    'ekaterinburg': '–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥',
                    'kazan': '–ö–∞–∑–∞–Ω—å',
                    'nizhniy_novgorod': '–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥',
                    'chelyabinsk': '–ß–µ–ª—è–±–∏–Ω—Å–∫',
                    'omsk': '–û–º—Å–∫',
                    'samara': '–°–∞–º–∞—Ä–∞',
                    'rostov-na-donu': '–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É',
                    'ufa': '–£—Ñ–∞',
                    'krasnoyarsk': '–ö—Ä–∞—Å–Ω–æ—è—Ä—Å–∫',
                    'voronezh': '–í–æ—Ä–æ–Ω–µ–∂',
                    'perm': '–ü–µ—Ä–º—å',
                    'volgograd': '–í–æ–ª–≥–æ–≥—Ä–∞–¥'
                }
                return region_map.get(region, region.replace('-', ' ').title())
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        except:
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
    
    def extract_mileage(self, soup, page_text):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–æ–±–µ–≥–∞"""
        try:
            # –ò—â–µ–º –ø—Ä–æ–±–µ–≥ –≤ —Ç–µ–∫—Å—Ç–µ
            mileage_patterns = [
                r'–ø—Ä–æ–±–µ–≥[^\d]*(\d[\d\s]*)\s*–∫–º',
                r'(\d[\d\s]*)\s*–∫–º[^.]*–ø—Ä–æ–±–µ–≥',
                r'–ø—Ä–æ–±–µ–≥</span>.*?<span[^>]*>.*?(\d[\d\s]*)\s*–∫–º',
                r'"mileage".*?"value".*?"(\d+)"'
            ]
            
            for pattern in mileage_patterns:
                matches = re.search(pattern, page_text, re.IGNORECASE | re.DOTALL)
                if matches:
                    mileage_str = matches.group(1).replace(' ', '')
                    if mileage_str.isdigit():
                        return int(mileage_str)
            
            return 0
            
        except Exception as e:
            logger.error(f"Mileage extraction error: {e}")
            return 0
    
    def analyze_ad(self, ad_data):
        """–ê–Ω–∞–ª–∏–∑ –æ–±—ä—è–≤–ª–µ–Ω–∏—è"""
        analysis = {
            'price_analysis': self.analyze_price(ad_data['price']),
            'photo_analysis': self.analyze_photos(ad_data['image_count']),
            'mileage_analysis': self.analyze_mileage(ad_data['mileage'], ad_data['year']),
            'year_analysis': self.analyze_year(ad_data['year']),
            'recommendations': []
        }
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        recommendations = self.generate_recommendations(ad_data, analysis)
        analysis['recommendations'] = recommendations
        
        # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
        analysis['overall_score'] = self.calculate_overall_score(ad_data, analysis)
        
        return analysis
    
    def analyze_price(self, price):
        """–ê–Ω–∞–ª–∏–∑ —Ü–µ–Ω—ã"""
        if price == 0:
            return {'emoji': '‚ùì', 'text': '–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞', 'score': 3}
        elif price < 100000:
            return {'emoji': 'üö®', 'text': '–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –Ω–∏–∑–∫–∞—è', 'score': 1}
        elif price < 300000:
            return {'emoji': 'üí∞', 'text': '–ù–∏–∑–∫–∞—è', 'score': 7}
        elif price < 800000:
            return {'emoji': 'üíµ', 'text': '–°—Ä–µ–¥–Ω—è—è', 'score': 8}
        elif price < 2000000:
            return {'emoji': 'üíé', 'text': '–í—ã—Å–æ–∫–∞—è', 'score': 6}
        else:
            return {'emoji': 'üèéÔ∏è', 'text': '–ü—Ä–µ–º–∏—É–º', 'score': 5}
    
    def analyze_photos(self, image_count):
        """–ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π"""
        if image_count == 0:
            return {'emoji': '‚ùå', 'text': '–ù–µ—Ç —Ñ–æ—Ç–æ', 'score': 1}
        elif image_count < 3:
            return {'emoji': '‚ö†Ô∏è', 'text': '–ú–∞–ª–æ —Ñ–æ—Ç–æ', 'score': 5}
        elif image_count < 6:
            return {'emoji': '‚úÖ', 'text': '–î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ', 'score': 8}
        else:
            return {'emoji': 'üì∏', 'text': '–ú–Ω–æ–≥–æ —Ñ–æ—Ç–æ', 'score': 9}
    
    def analyze_mileage(self, mileage, year):
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–µ–≥–∞"""
        if mileage == 0:
            return {'emoji': '‚ùì', 'text': '–ù–µ —É–∫–∞–∑–∞–Ω', 'score': 5}
        
        car_age = 2024 - year
        if car_age <= 0:
            car_age = 1
        
        avg_mileage_per_year = mileage / car_age
        
        if avg_mileage_per_year < 10000:
            return {'emoji': 'üëç', 'text': '–ù–∏–∑–∫–∏–π –ø—Ä–æ–±–µ–≥', 'score': 9}
        elif avg_mileage_per_year < 20000:
            return {'emoji': '‚úÖ', 'text': '–ù–æ—Ä–º–∞–ª—å–Ω—ã–π –ø—Ä–æ–±–µ–≥', 'score': 7}
        elif avg_mileage_per_year < 30000:
            return {'emoji': '‚ö†Ô∏è', 'text': '–í—ã—Å–æ–∫–∏–π –ø—Ä–æ–±–µ–≥', 'score': 4}
        else:
            return {'emoji': 'üö®', 'text': '–û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π –ø—Ä–æ–±–µ–≥', 'score': 2}
    
    def analyze_year(self, year):
        """–ê–Ω–∞–ª–∏–∑ –≥–æ–¥–∞ –≤—ã–ø—É—Å–∫–∞"""
        car_age = 2024 - year
        
        if car_age <= 3:
            return {'emoji': 'üÜï', 'text': '–ù–æ–≤—ã–π', 'score': 9}
        elif car_age <= 7:
            return {'emoji': '‚úÖ', 'text': '–°—Ä–µ–¥–Ω–∏–π –≤–æ–∑—Ä–∞—Å—Ç', 'score': 7}
        elif car_age <= 12:
            return {'emoji': '‚ö†Ô∏è', 'text': '–°—Ç–∞—Ä—ã–π', 'score': 5}
        else:
            return {'emoji': 'üöó', 'text': '–í–µ—Ç–µ—Ä–∞–Ω', 'score': 3}
    
    def calculate_overall_score(self, ad_data, analysis):
        """–†–∞—Å—á–µ—Ç –æ–±—â–µ–π –æ—Ü–µ–Ω–∫–∏"""
        scores = [
            analysis['price_analysis']['score'],
            analysis['photo_analysis']['score'],
            analysis['mileage_analysis']['score'],
            analysis['year_analysis']['score']
        ]
        
        return round(sum(scores) / len(scores))
    
    def generate_recommendations(self, ad_data, analysis):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        recommendations = []
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ñ–æ—Ç–æ
        if ad_data['image_count'] == 0:
            recommendations.append("‚ùå *–ù–µ—Ç —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π* - –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∑–∞–ø—Ä–æ—Å–∏—Ç–µ —É –ø—Ä–æ–¥–∞–≤—Ü–∞")
        elif ad_data['image_count'] < 3:
            recommendations.append("‚ö†Ô∏è *–ú–∞–ª–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π* - –ø–æ–ø—Ä–æ—Å–∏—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–æ—Ç–æ")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ü–µ–Ω–µ
        if ad_data['price'] == 0:
            recommendations.append("‚ùì *–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞* - —É—Ç–æ—á–Ω–∏—Ç–µ —Å—Ç–æ–∏–º–æ—Å—Ç—å")
        elif ad_data['price'] < 100000:
            recommendations.append("üö® *–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –Ω–∏–∑–∫–∞—è —Ü–µ–Ω–∞* - –±—É–¥—å—Ç–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã, –≤–æ–∑–º–æ–∂–Ω—ã —Å–∫—Ä—ã—Ç—ã–µ –¥–µ—Ñ–µ–∫—Ç—ã")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—Ä–æ–±–µ–≥—É
        if ad_data['mileage'] > 0:
            car_age = 2024 - ad_data['year']
            if car_age > 0:
                avg_mileage = ad_data['mileage'] / car_age
                if avg_mileage > 30000:
                    recommendations.append("‚ö†Ô∏è *–û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π –ø—Ä–æ–±–µ–≥* - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–≤–∏–≥–∞—Ç–µ–ª—è –∏ —Ö–æ–¥–æ–≤–æ–π")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≥–æ–¥—É
        if 2024 - ad_data['year'] > 15:
            recommendations.append("üï∞Ô∏è *–ê–≤—Ç–æ–º–æ–±–∏–ª—å —Å—Ç–∞—Ä—à–µ 15 –ª–µ—Ç* - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ")
        
        if not recommendations:
            recommendations.append("‚úÖ *–û–±—ä—è–≤–ª–µ–Ω–∏–µ –≤—ã–≥–ª—è–¥–∏—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ* - –º–æ–∂–Ω–æ –¥–æ–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å—Å—è –æ –æ—Å–º–æ—Ç—Ä–µ")
        
        return recommendations
    
    def generate_report(self, ad_data, analysis):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞"""
        
        report = f"""
üöó *{ad_data['title']}*

üí∞ *–¶–µ–Ω–∞:* {ad_data['price']:,} —Ä—É–±. {analysis['price_analysis']['emoji']}
üìÖ *–ì–æ–¥:* {ad_data['year']} {analysis['year_analysis']['emoji']}
üèÅ *–ü—Ä–æ–±–µ–≥:* {ad_data['mileage']:,} –∫–º {analysis['mileage_analysis']['emoji']}
üìç *–†–µ–≥–∏–æ–Ω:* {ad_data['region']}
üì∏ *–§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏:* {ad_data['image_count']} {analysis['photo_analysis']['emoji']}

‚≠ê *–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞:* {analysis['overall_score']}/10

üìä *–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑:*
‚Ä¢ –¶–µ–Ω–∞: {analysis['price_analysis']['text']}
‚Ä¢ –§–æ—Ç–æ: {analysis['photo_analysis']['text']}
‚Ä¢ –ü—Ä–æ–±–µ–≥: {analysis['mileage_analysis']['text']}
‚Ä¢ –í–æ–∑—Ä–∞—Å—Ç: {analysis['year_analysis']['text']}

üí° *–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:*
"""
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        for rec in analysis['recommendations']:
            report += f"‚Ä¢ {rec}\n"
        
        report += f"""
üîç *–°–æ–≤–µ—Ç—ã –ø–æ –æ—Å–º–æ—Ç—Ä—É:*
‚Ä¢ –í—Å–µ–≥–¥–∞ –æ—Å–º–∞—Ç—Ä–∏–≤–∞–π—Ç–µ –∞–≤—Ç–æ–º–æ–±–∏–ª—å –ª–∏—á–Ω–æ
‚Ä¢ –ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ VIN
‚Ä¢ –°–¥–µ–ª–∞–π—Ç–µ —Ç–µ—Å—Ç-–¥—Ä–∞–π–≤
‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å—Ç–æ—Ä–∏—é —á–µ—Ä–µ–∑ –æ–Ω–ª–∞–π–Ω-—Å–µ—Ä–≤–∏—Å—ã
‚Ä¢ –û—Å–º–æ—Ç—Ä–∏—Ç–µ –∫—É–∑–æ–≤ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç —Ä–∂–∞–≤—á–∏–Ω—ã –∏ –≤–º—è—Ç–∏–Ω

üéØ *–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:*
–°–≤—è–∂–∏—Ç–µ—Å—å —Å –ø—Ä–æ–¥–∞–≤—Ü–æ–º –∏ –¥–æ–≥–æ–≤–æ—Ä–∏—Ç–µ—Å—å –æ –æ—Å–º–æ—Ç—Ä–µ!
        """
        
        return report
    
    def handle_text(self, message):
        chat_id = message.chat.id
        text = message.text
        
        if text == 'üîç –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä—è–≤–ª–µ–Ω–∏–µ':
            self.bot.send_message(
                chat_id,
                "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ —Å –ê–≤–∏—Ç–æ\n\n*–ü—Ä–∏–º–µ—Ä:*\n`https://www.avito.ru/moskva/avtomobili/volkswagen_golf_2018...`",
                parse_mode='Markdown'
            )
        
        elif text == '‚ÑπÔ∏è –ü–æ–º–æ—â—å':
            help_text = """
ü§ñ *AutoInspect Bot - –ü–æ–º–æ—â—å*

*–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:*
1. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ —Å –ê–≤–∏—Ç–æ
2. –Ø –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
3. –í—ã –ø–æ–ª—É—á–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏

*–ß—Ç–æ —è –ø—Ä–æ–≤–µ—Ä—è—é:*
‚Ä¢ üìä –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–≤—Ç–æ–º–æ–±–∏–ª—è
‚Ä¢ üí∞ –ê–¥–µ–∫–≤–∞—Ç–Ω–æ—Å—Ç—å —Ü–µ–Ω—ã
‚Ä¢ üì∏ –ù–∞–ª–∏—á–∏–µ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π
‚Ä¢ üèÅ –ü—Ä–æ–±–µ–≥ –∏ –µ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –≤–æ–∑—Ä–∞—Å—Ç—É
‚Ä¢ üìÖ –ì–æ–¥ –≤—ã–ø—É—Å–∫–∞ –∏ –≤–æ–∑—Ä–∞—Å—Ç –∞–≤—Ç–æ–º–æ–±–∏–ª—è
‚Ä¢ üìç –†–µ–≥–∏–æ–Ω –ø—Ä–æ–¥–∞–∂–∏

*–ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã:*
–û—Ç–ø—Ä–∞–≤—å—Ç–µ: `https://www.avito.ru/moskva/avtomobili/volkswagen_golf_2018...`

*–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:* –Ø —Ç–æ–ª—å–∫–æ –ø–æ–º–æ–≥–∞—é —Å –ø–µ—Ä–≤–∏—á–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º. –í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –∞–≤—Ç–æ–º–æ–±–∏–ª—å –ª–∏—á–Ω–æ!
            """
            self.bot.send_message(chat_id, help_text, parse_mode='Markdown')
        
        else:
            self.bot.send_message(
                chat_id,
                "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –Ω–∏–∂–µ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ —Å –ê–≤–∏—Ç–æ üëá"
            )
    
    def run(self):
        """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
        logger.info("üöÄ Starting AutoInspect Bot...")
        try:
            self.bot.infinity_polling(timeout=60, long_polling_timeout=60)
        except Exception as e:
            logger.error(f"‚ùå Bot crashed: {e}")
            raise

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if __name__ == "__main__":
    # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    token = os.getenv('BOT_TOKEN')
    
    if not token:
        logger.error("‚ùå BOT_TOKEN environment variable is not set!")
        logger.error("Please set BOT_TOKEN in your environment variables")
        exit(1)
    
    # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞
    bot = SimpleAvitoBot(token)
    bot.run()
