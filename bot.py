# bot.py - –ü–û–õ–ù–´–ô –ö–û–î –° –ü–û–î–î–ï–†–ñ–ö–û–ô –ê–í–ò–¢–û –ò DROM
import os
import telebot
from telebot import types
import logging
import requests
from bs4 import BeautifulSoup
import re
import json
import time

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def reset_webhook(token):
    """–°–±—Ä–æ—Å webhook —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å polling"""
    try:
        url = f"https://api.telegram.org/bot{token}/deleteWebhook"
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            logger.info("‚úÖ Webhook reset successfully")
        else:
            logger.warning("‚ö†Ô∏è Could not reset webhook")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Webhook reset failed: {e}")

class SimpleAvitoBot:
    def __init__(self, token):
        self.bot = telebot.TeleBot(token)
        self.setup_handlers()
        logger.info("‚úÖ Bot initialized successfully!")
    
    def setup_handlers(self):
        @self.bot.message_handler(commands=['start', 'help'])
        def start_handler(message):
            self.handle_start(message)
        
        @self.bot.message_handler(regexp=r'https?://(www\.)?avito\.ru/.*')
        def avito_url_handler(message):
            self.handle_avito_url(message)
        
        @self.bot.message_handler(regexp=r'https?://(www\.)?drom\.ru/.*')
        def drom_url_handler(message):
            self.handle_drom_url(message)
        
        @self.bot.message_handler(func=lambda message: True)
        def text_handler(message):
            self.handle_text(message)
    
    def handle_start(self, message):
        chat_id = message.chat.id
        
        markup = types.ReplyKeyboardMarkup(resize_keyboard=True)
        markup.add('üîç –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä—è–≤–ª–µ–Ω–∏–µ')
        markup.add('‚ÑπÔ∏è –ü–æ–º–æ—â—å')
        
        welcome_text = """
üöó *AutoInspect Bot*

–í–∞—à –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–π —Å:
‚Ä¢ üÖ∞Ô∏è –ê–≤–∏—Ç–æ
‚Ä¢ üá© Drom.ru

*–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:*
1. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ
2. –ü–æ–ª—É—á–∏—Ç–µ –±–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑  
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

*–ü—Ä–∏–º–µ—Ä—ã —Å—Å—ã–ª–æ–∫:*
`https://www.avito.ru/...`
`https://auto.drom.ru/...`

–ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –Ω–∏–∂–µ —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å! üëá
        """
        
        self.bot.send_message(
            chat_id,
            welcome_text,
            reply_markup=markup,
            parse_mode='Markdown'
        )
    
    def handle_avito_url(self, message):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Å—ã–ª–æ–∫ —Å –ê–≤–∏—Ç–æ"""
        chat_id = message.chat.id
        url = message.text
        
        logger.info(f"üîó Received Avito URL: {url}")
        
        try:
            status_msg = self.bot.send_message(
                chat_id, 
                "üîç *–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –æ–±—ä—è–≤–ª–µ–Ω–∏–µ —Å –ê–≤–∏—Ç–æ...*", 
                parse_mode='Markdown'
            )
            
            self.bot.edit_message_text(
                "üì¶ *–ü–æ–ª—É—á–∞—é –¥–∞–Ω–Ω—ã–µ...*",
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            ad_data = self.parse_avito_ad(url)
            
            if not ad_data:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è")
            
            self.bot.edit_message_text(
                "üìä *–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é...*",
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            analysis = self.analyze_ad(ad_data)
            
            self.bot.edit_message_text(
                "üìù *–§–æ—Ä–º–∏—Ä—É—é –æ—Ç—á–µ—Ç...*",
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            report = self.generate_report(ad_data, analysis)
            
            self.bot.edit_message_text(
                report,
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            logger.info(f"‚úÖ Avito analysis completed: {url}")
            
        except Exception as e:
            logger.error(f"‚ùå Avito analysis failed: {e}")
            error_msg = f"‚ùå *–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ê–≤–∏—Ç–æ:* {str(e)}"
            try:
                self.bot.edit_message_text(
                    error_msg,
                    chat_id,
                    status_msg.message_id,
                    parse_mode='Markdown'
                )
            except:
                self.bot.send_message(chat_id, error_msg, parse_mode='Markdown')
    
    def handle_drom_url(self, message):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Å—ã–ª–æ–∫ —Å Drom.ru"""
        chat_id = message.chat.id
        url = message.text
        
        logger.info(f"üîó Received Drom URL: {url}")
        
        try:
            status_msg = self.bot.send_message(
                chat_id, 
                "üîç *–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –æ–±—ä—è–≤–ª–µ–Ω–∏–µ —Å Drom...*", 
                parse_mode='Markdown'
            )
            
            self.bot.edit_message_text(
                "üì¶ *–ü–æ–ª—É—á–∞—é –¥–∞–Ω–Ω—ã–µ...*",
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            ad_data = self.parse_drom_ad(url)
            
            if not ad_data:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è")
            
            self.bot.edit_message_text(
                "üìä *–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é...*",
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            analysis = self.analyze_ad(ad_data)
            
            self.bot.edit_message_text(
                "üìù *–§–æ—Ä–º–∏—Ä—É—é –æ—Ç—á–µ—Ç...*",
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            report = self.generate_report(ad_data, analysis)
            
            self.bot.edit_message_text(
                report,
                chat_id,
                status_msg.message_id,
                parse_mode='Markdown'
            )
            
            logger.info(f"‚úÖ Drom analysis completed: {url}")
            
        except Exception as e:
            logger.error(f"‚ùå Drom analysis failed: {e}")
            error_msg = f"‚ùå *–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ Drom:* {str(e)}"
            try:
                self.bot.edit_message_text(
                    error_msg,
                    chat_id,
                    status_msg.message_id,
                    parse_mode='Markdown'
                )
            except:
                self.bot.send_message(chat_id, error_msg, parse_mode='Markdown')
    
    def parse_avito_ad(self, url):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å –ê–≤–∏—Ç–æ"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            }
            
            response = requests.get(url, headers=headers, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            title = self.extract_avito_title(soup)
            # –¶–µ–Ω–∞
            price = self.extract_avito_price(soup, response.text)
            # –§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
            images = self.extract_avito_images(soup)
            # –ì–æ–¥
            year = self.extract_year(title)
            # –†–µ–≥–∏–æ–Ω
            region = self.extract_avito_region(url)
            
            return {
                'title': title,
                'price': price,
                'year': year,
                'region': region,
                'image_count': len(images),
                'images': images[:5],
                'url': url,
                'source': 'avito'
            }
            
        except Exception as e:
            logger.error(f"‚ùå Avito parsing failed: {e}")
            return None
    
    def parse_drom_ad(self, url):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å Drom.ru"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            }
            
            response = requests.get(url, headers=headers, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            title = self.extract_drom_title(soup)
            # –¶–µ–Ω–∞
            price = self.extract_drom_price(soup, response.text)
            # –§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
            images = self.extract_drom_images(soup)
            # –ì–æ–¥
            year = self.extract_drom_year(soup, title)
            # –†–µ–≥–∏–æ–Ω
            region = self.extract_drom_region(soup)
            
            return {
                'title': title,
                'price': price,
                'year': year,
                'region': region,
                'image_count': len(images),
                'images': images[:5],
                'url': url,
                'source': 'drom'
            }
            
        except Exception as e:
            logger.error(f"‚ùå Drom parsing failed: {e}")
            return None
    
    def extract_avito_title(self, soup):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Å –ê–≤–∏—Ç–æ"""
        try:
            selectors = [
                'h1[data-marker="item-view/title"]',
                'h1.title-info-title',
                'h1',
                '.title-info-title-text',
                '[data-marker="item-view/title"]'
            ]
            
            for selector in selectors:
                element = soup.select_one(selector)
                if element and element.get_text(strip=True):
                    return element.get_text(strip=True)
            
            meta_title = soup.find('meta', property='og:title')
            if meta_title and meta_title.get('content'):
                return meta_title['content']
            
            page_title = soup.find('title')
            if page_title:
                return page_title.get_text(strip=True)
            
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å"
            
        except Exception as e:
            logger.error(f"Avito title error: {e}")
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å"
    
    def extract_drom_title(self, soup):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Å Drom"""
        try:
            selectors = [
                'h1[class*="title"]',
                '.css-1tjirrw',
                'h1',
                '[data-ftid="component_ad_title"]'
            ]
            
            for selector in selectors:
                element = soup.select_one(selector)
                if element and element.get_text(strip=True):
                    return element.get_text(strip=True)
            
            meta_title = soup.find('meta', property='og:title')
            if meta_title and meta_title.get('content'):
                return meta_title['content']
            
            page_title = soup.find('title')
            if page_title:
                return page_title.get_text(strip=True)
            
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å"
            
        except Exception as e:
            logger.error(f"Drom title error: {e}")
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å"
    
    def extract_avito_price(self, soup, page_text):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω—ã —Å –ê–≤–∏—Ç–æ"""
        try:
            price_selectors = [
                'meta[itemprop="price"]',
                'span[data-marker="item-view/item-price"]',
                '[data-marker="item-view/item-price"]',
                '.js-item-price',
                '.price-value',
            ]
            
            for selector in price_selectors:
                element = soup.select_one(selector)
                if element:
                    if element.get('content'):
                        price_str = element['content']
                        if price_str.isdigit():
                            return int(price_str)
                    
                    price_text = element.get_text(strip=True)
                    numbers = re.findall(r'\d+', price_text.replace(' ', ''))
                    if numbers:
                        return int(''.join(numbers))
            
            # –ü–æ–∏—Å–∫ –≤ JSON-LD
            json_ld = soup.find('script', type='application/ld+json')
            if json_ld:
                try:
                    data = json.loads(json_ld.string)
                    if 'offers' in data and 'price' in data['offers']:
                        return int(data['offers']['price'])
                except:
                    pass
            
            # –ü–æ–∏—Å–∫ –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            price_patterns = [
                r'"price":\s*"(\d+)"',
                r'"price":\s*(\d+)',
                r'itemprop="price".*?content="(\d+)"',
            ]
            
            for pattern in price_patterns:
                matches = re.search(pattern, page_text, re.IGNORECASE | re.DOTALL)
                if matches:
                    price_str = matches.group(1).replace(' ', '')
                    if price_str.isdigit():
                        return int(price_str)
            
            return 0
            
        except Exception as e:
            logger.error(f"Avito price error: {e}")
            return 0
    
    def extract_drom_price(self, soup, page_text):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω—ã —Å Drom"""
        try:
            price_selectors = [
                '[data-ftid="component_price"]',
                '.css-1dv8a3k',
                '.css-1v9f1fg',
                '[class*="price"]'
            ]
            
            for selector in price_selectors:
                element = soup.select_one(selector)
                if element:
                    price_text = element.get_text(strip=True)
                    numbers = re.findall(r'\d+', price_text.replace(' ', ''))
                    if numbers:
                        return int(''.join(numbers))
            
            # –ü–æ–∏—Å–∫ –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            price_patterns = [
                r'"price":\s*"(\d+)"',
                r'"price":\s*(\d+)',
                r'—Ü–µ–Ω–∞.*?(\d[\d\s]*)\s*‚ÇΩ',
            ]
            
            for pattern in price_patterns:
                matches = re.search(pattern, page_text, re.IGNORECASE | re.DOTALL)
                if matches:
                    price_str = matches.group(1).replace(' ', '')
                    if price_str.isdigit():
                        return int(price_str)
            
            return 0
            
        except Exception as e:
            logger.error(f"Drom price error: {e}")
            return 0
    
    def extract_avito_images(self, soup):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ê–≤–∏—Ç–æ"""
        try:
            images = []
            
            img_selectors = [
                'img[data-src]',
                'img[src*="avito"]',
                '.gallery-img-cover img',
                '[data-marker="image-frame/image"]',
            ]
            
            for selector in img_selectors:
                img_elements = soup.select(selector)
                for img in img_elements[:10]:
                    src = img.get('data-src') or img.get('src')
                    if src and src.startswith('http'):
                        if src.startswith('//'):
                            src = 'https:' + src
                        images.append(src)
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            unique_images = []
            for img in images:
                if img not in unique_images:
                    unique_images.append(img)
            
            return unique_images
            
        except Exception as e:
            logger.error(f"Avito images error: {e}")
            return []
    
    def extract_drom_images(self, soup):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å Drom"""
        try:
            images = []
            
            img_selectors = [
                'img[src*="drom"]',
                '.css-1bm2a1l img',
                '.b-album__item img',
                '[data-ftid="component_gallery_image"]'
            ]
            
            for selector in img_selectors:
                img_elements = soup.select(selector)
                for img in img_elements[:10]:
                    src = img.get('src')
                    if src and src.startswith('http'):
                        if src.startswith('//'):
                            src = 'https:' + src
                        images.append(src)
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            unique_images = []
            for img in images:
                if img not in unique_images:
                    unique_images.append(img)
            
            return unique_images
            
        except Exception as e:
            logger.error(f"Drom images error: {e}")
            return []
    
    def extract_year(self, title):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥–æ–¥–∞ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        try:
            year_match = re.search(r'\b(19|20)\d{2}\b', title)
            return int(year_match.group()) if year_match else 2020
        except:
            return 2020
    
    def extract_drom_year(self, soup, title):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥–æ–¥–∞ —Å Drom"""
        try:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            year_match = re.search(r'\b(19|20)\d{2}\b', title)
            if year_match:
                return int(year_match.group())
            
            # –ò—â–µ–º –≤ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ö
            year_selectors = [
                '[data-ftid="component_inline-param"]',
                '.css-1ei9tni',
                '[class*="year"]'
            ]
            
            for selector in year_selectors:
                elements = soup.select(selector)
                for element in elements:
                    text = element.get_text()
                    year_match = re.search(r'\b(19|20)\d{2}\b', text)
                    if year_match:
                        return int(year_match.group())
            
            return 2020
            
        except:
            return 2020
    
    def extract_avito_region(self, url):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞ –∏–∑ URL –ê–≤–∏—Ç–æ"""
        try:
            match = re.search(r'avito\.ru/([^/]+)', url)
            if match:
                region = match.group(1)
                region_map = {
                    'moskva': '–ú–æ—Å–∫–≤–∞',
                    'sankt-peterburg': '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥',
                    'spb': '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥',
                    'novosibirsk': '–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫',
                    'ekaterinburg': '–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥',
                    'kazan': '–ö–∞–∑–∞–Ω—å',
                }
                return region_map.get(region, region.replace('-', ' ').title())
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        except:
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
    
    def extract_drom_region(self, soup):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞ —Å Drom"""
        try:
            region_selectors = [
                '[data-ftid="component_seller_location"]',
                '.css-1l12n0z',
                '[class*="location"]'
            ]
            
            for selector in region_selectors:
                element = soup.select_one(selector)
                if element:
                    region_text = element.get_text(strip=True)
                    if region_text:
                        return region_text
            
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        except:
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
    
    def analyze_ad(self, ad_data):
        """–ê–Ω–∞–ª–∏–∑ –æ–±—ä—è–≤–ª–µ–Ω–∏—è"""
        analysis = {
            'price_analysis': self.analyze_price(ad_data['price']),
            'photo_analysis': self.analyze_photos(ad_data['image_count']),
            'year_analysis': self.analyze_year(ad_data['year']),
            'recommendations': []
        }
        
        recommendations = self.generate_recommendations(ad_data, analysis)
        analysis['recommendations'] = recommendations
        
        analysis['overall_score'] = self.calculate_overall_score(ad_data, analysis)
        
        return analysis
    
    def analyze_price(self, price):
        if price == 0:
            return {'emoji': '‚ùì', 'text': '–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞', 'score': 3}
        elif price < 100000:
            return {'emoji': 'üö®', 'text': '–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –Ω–∏–∑–∫–∞—è', 'score': 1}
        elif price < 300000:
            return {'emoji': 'üí∞', 'text': '–ù–∏–∑–∫–∞—è', 'score': 7}
        elif price < 800000:
            return {'emoji': 'üíµ', 'text': '–°—Ä–µ–¥–Ω—è—è', 'score': 8}
        elif price < 2000000:
            return {'emoji': 'üíé', 'text': '–í—ã—Å–æ–∫–∞—è', 'score': 6}
        else:
            return {'emoji': 'üèéÔ∏è', 'text': '–ü—Ä–µ–º–∏—É–º', 'score': 5}
    
    def analyze_photos(self, image_count):
        if image_count == 0:
            return {'emoji': '‚ùå', 'text': '–ù–µ—Ç —Ñ–æ—Ç–æ', 'score': 1}
        elif image_count < 3:
            return {'emoji': '‚ö†Ô∏è', 'text': '–ú–∞–ª–æ —Ñ–æ—Ç–æ', 'score': 5}
        elif image_count < 6:
            return {'emoji': '‚úÖ', 'text': '–î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ', 'score': 8}
        else:
            return {'emoji': 'üì∏', 'text': '–ú–Ω–æ–≥–æ —Ñ–æ—Ç–æ', 'score': 9}
    
    def analyze_year(self, year):
        car_age = 2024 - year
        
        if car_age <= 3:
            return {'emoji': 'üÜï', 'text': '–ù–æ–≤—ã–π', 'score': 9}
        elif car_age <= 7:
            return {'emoji': '‚úÖ', 'text': '–°—Ä–µ–¥–Ω–∏–π –≤–æ–∑—Ä–∞—Å—Ç', 'score': 7}
        elif car_age <= 12:
            return {'emoji': '‚ö†Ô∏è', 'text': '–°—Ç–∞—Ä—ã–π', 'score': 5}
        else:
            return {'emoji': 'üöó', 'text': '–í–µ—Ç–µ—Ä–∞–Ω', 'score': 3}
    
    def calculate_overall_score(self, ad_data, analysis):
        scores = [
            analysis['price_analysis']['score'],
            analysis['photo_analysis']['score'],
            analysis['year_analysis']['score']
        ]
        
        return round(sum(scores) / len(scores))
    
    def generate_recommendations(self, ad_data, analysis):
        recommendations = []
        
        if ad_data['image_count'] == 0:
            recommendations.append("‚ùå *–ù–µ—Ç —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π* - –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∑–∞–ø—Ä–æ—Å–∏—Ç–µ —É –ø—Ä–æ–¥–∞–≤—Ü–∞")
        elif ad_data['image_count'] < 3:
            recommendations.append("‚ö†Ô∏è *–ú–∞–ª–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π* - –ø–æ–ø—Ä–æ—Å–∏—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–æ—Ç–æ")
        
        if ad_data['price'] == 0:
            recommendations.append("‚ùì *–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞* - —É—Ç–æ—á–Ω–∏—Ç–µ —Å—Ç–æ–∏–º–æ—Å—Ç—å")
        elif ad_data['price'] < 100000:
            recommendations.append("üö® *–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –Ω–∏–∑–∫–∞—è —Ü–µ–Ω–∞* - –±—É–¥—å—Ç–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã")
        
        if 2024 - ad_data['year'] > 15:
            recommendations.append("üï∞Ô∏è *–ê–≤—Ç–æ–º–æ–±–∏–ª—å —Å—Ç–∞—Ä—à–µ 15 –ª–µ—Ç* - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ")
        
        if not recommendations:
            recommendations.append("‚úÖ *–û–±—ä—è–≤–ª–µ–Ω–∏–µ –≤—ã–≥–ª—è–¥–∏—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ* - –º–æ–∂–Ω–æ –¥–æ–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å—Å—è –æ –æ—Å–º–æ—Ç—Ä–µ")
        
        return recommendations
    
    def generate_report(self, ad_data, analysis):
        source_emoji = "üÖ∞Ô∏è" if ad_data['source'] == 'avito' else "üá©"
        
        report = f"""
{source_emoji} *{ad_data['title']}*

üí∞ *–¶–µ–Ω–∞:* {ad_data['price']:,} —Ä—É–±. {analysis['price_analysis']['emoji']}
üìÖ *–ì–æ–¥:* {ad_data['year']} {analysis['year_analysis']['emoji']}
üìç *–†–µ–≥–∏–æ–Ω:* {ad_data['region']}
üì∏ *–§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏:* {ad_data['image_count']} {analysis['photo_analysis']['emoji']}

‚≠ê *–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞:* {analysis['overall_score']}/10

üìä *–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑:*
‚Ä¢ –¶–µ–Ω–∞: {analysis['price_analysis']['text']}
‚Ä¢ –§–æ—Ç–æ: {analysis['photo_analysis']['text']}
‚Ä¢ –í–æ–∑—Ä–∞—Å—Ç: {analysis['year_analysis']['text']}

üí° *–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:*
"""
        
        for rec in analysis['recommendations']:
            report += f"‚Ä¢ {rec}\n"
        
        report += f"""
üîç *–°–æ–≤–µ—Ç—ã –ø–æ –æ—Å–º–æ—Ç—Ä—É:*
‚Ä¢ –í—Å–µ–≥–¥–∞ –æ—Å–º–∞—Ç—Ä–∏–≤–∞–π—Ç–µ –∞–≤—Ç–æ–º–æ–±–∏–ª—å –ª–∏—á–Ω–æ
‚Ä¢ –ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ VIN
‚Ä¢ –°–¥–µ–ª–∞–π—Ç–µ —Ç–µ—Å—Ç-–¥—Ä–∞–π–≤
‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å—Ç–æ—Ä–∏—é —á–µ—Ä–µ–∑ –æ–Ω–ª–∞–π–Ω-—Å–µ—Ä–≤–∏—Å—ã

üéØ *–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:*
–°–≤—è–∂–∏—Ç–µ—Å—å —Å –ø—Ä–æ–¥–∞–≤—Ü–æ–º –∏ –¥–æ–≥–æ–≤–æ—Ä–∏—Ç–µ—Å—å –æ –æ—Å–º–æ—Ç—Ä–µ!
        """
        
        return report
    
    def handle_text(self, message):
        chat_id = message.chat.id
        text = message.text
        
        if text == 'üîç –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä—è–≤–ª–µ–Ω–∏–µ':
            self.bot.send_message(
                chat_id,
                "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ:\n\n*–ê–≤–∏—Ç–æ:*\n`https://www.avito.ru/...`\n\n*Drom:*\n`https://auto.drom.ru/...`",
                parse_mode='Markdown'
            )
        
        elif text == '‚ÑπÔ∏è –ü–æ–º–æ—â—å':
            help_text = """
ü§ñ *AutoInspect Bot - –ü–æ–º–æ—â—å*

*–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–ª–æ—â–∞–¥–∫–∏:*
‚Ä¢ üÖ∞Ô∏è –ê–≤–∏—Ç–æ (avito.ru)
‚Ä¢ üá© Drom.ru (auto.drom.ru)

*–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:*
1. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ
2. –Ø –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
3. –í—ã –ø–æ–ª—É—á–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏

*–ß—Ç–æ —è –ø—Ä–æ–≤–µ—Ä—è—é:*
‚Ä¢ üìä –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–≤—Ç–æ–º–æ–±–∏–ª—è
‚Ä¢ üí∞ –ê–¥–µ–∫–≤–∞—Ç–Ω–æ—Å—Ç—å —Ü–µ–Ω—ã
‚Ä¢ üì∏ –ù–∞–ª–∏—á–∏–µ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π
‚Ä¢ üìÖ –ì–æ–¥ –≤—ã–ø—É—Å–∫–∞ –∏ –≤–æ–∑—Ä–∞—Å—Ç –∞–≤—Ç–æ–º–æ–±–∏–ª—è
‚Ä¢ üìç –†–µ–≥–∏–æ–Ω –ø—Ä–æ–¥–∞–∂–∏

*–ü—Ä–∏–º–µ—Ä—ã —Å—Å—ã–ª–æ–∫:*
`https://www.avito.ru/moskva/avtomobili/...`
`https://auto.drom.ru/volkswagen/golf/...`

*–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:* –Ø —Ç–æ–ª—å–∫–æ –ø–æ–º–æ–≥–∞—é —Å –ø–µ—Ä–≤–∏—á–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º. –í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –∞–≤—Ç–æ–º–æ–±–∏–ª—å –ª–∏—á–Ω–æ!
            """
            self.bot.send_message(chat_id, help_text, parse_mode='Markdown')
        
        else:
            self.bot.send_message(
                chat_id,
                "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –Ω–∏–∂–µ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ —Å –ê–≤–∏—Ç–æ –∏–ª–∏ Drom üëá"
            )
    
    def run(self):
        """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        logger.info("üöÄ Starting AutoInspect Bot...")
        
        max_retries = 3
        retry_delay = 10
        
        for attempt in range(max_retries):
            try:
                logger.info(f"üîÑ Attempt {attempt + 1} to start bot...")
                self.bot.infinity_polling(timeout=60, long_polling_timeout=60)
                break
            except Exception as e:
                logger.error(f"‚ùå Bot crashed on attempt {attempt + 1}: {e}")
                
                if attempt < max_retries - 1:
                    logger.info(f"üïê Retrying in {retry_delay} seconds...")
                    time.sleep(retry_delay)
                    retry_delay *= 2
                else:
                    logger.error("‚ùå All retry attempts failed. Bot stopped.")
                    raise

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if __name__ == "__main__":
    token = os.getenv('BOT_TOKEN')
    
    if not token:
        logger.error("‚ùå BOT_TOKEN environment variable is not set!")
        exit(1)
    
    # –°–±—Ä–æ—Å webhook –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º
    reset_webhook(token)
    
    # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏–∏ —Å–±—Ä–æ—Å–∞ webhook
    time.sleep(2)
    
    # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞
    bot = SimpleAvitoBot(token)
    bot.run()
